%! Author = mkeim
%! Date = 7/18/24

\section{RP1: Statistically Significant Detection of Linguistic Change} \label{sec:paper_kulkarni}
\subsection{Introduction} \label{subsec:introduction}
This research aims to quantify linguistic shifts in word meaning and usage across time, focusing on semantic or contextual changes.
To understand data voids, we are sure that a change is happening, but we need to understand the change that is happening over time.
Also after knowing that a change has occurred, we would like to know when did that change really occur so that we can co-relate that the data void occured when a political event happened or how the COVID outbreak event,
which could help us identify that the term were introduced due to that event, which can be a future direction we can look into.
This paper is exciting because the ideas inspired me to pursue this project and get future directions as well.

Their approach focuses on three methods to construct time series for a word.
The first one is based on frequency, which captures sudden changes in word usage.
In our work, this corresponds to strategic new terms data voids or breaking news data void,
where breaking news data void shows that there's comes a sudden change in a word activity whenever's there an event happen.
For example, the term "filmyourhospital" was introduced in during 2020 when coronavirus took place, which corresponds to a sudden spike.
And this term was never used before 2020, making it a new term that introduced to support the conspiracy theory regarding encouraged people to visit local hospitals to take pictures and videos of empty hospitals to help “prove” that the COVID-19 pandemic is an elaborate hoax.

Their second method is Syntactic method where they analyze each word's part of speech tag.

And last method is distributional method which captures overall usage of word using word co-occurence.
This type of method can help us identify data voids which have changed their meaning over time, such as Fragmented Concepts or Outdated Terms DV.

They apply these techniques on three different domains: books, tweets and reviews.

The study utilizes diverse datasets, including Twitter posts, Amazon product reviews, and Google Book Ngrams, to construct time series for individual words.
Three distinct methods are employed for statistical modeling.

\begin{itemize}
    \item \para{RQ1.} \emph{What methods can quantify the statistical relevance of observed changes in a word's usage across different time periods?}
    \item \para{RQ2.} \emph{Given that a word's usage has changed, how can the precise moment or period of this shift be determined?}
\end{itemize}



