%! Author = mkeim
%! Date = 7/11/24

\section{Related Work} \label{sec:relatedwork}
\para{Tracking how word meaning change over time.}
The evolution of word meanings over time has been a subject of significant interest.
Researchers employed a diverse array of methodologies, including \emph{word embeddings} ~\cite{kulkarni2014statisticallysignificantdetectionlinguistic},
\emph{neural language models} ~\cite{kim-etal-2014-temporal}, and \emph{diachronic analysis} ~\cite{hamilton-etal-2016-diachronic, kutuzov-etal-2018-diachronic},
to track and examine semantic shifts across historical periods.
Much of this research utilized the \emph{Google Books Ngram corpus}
~\cite{gulordava-baroni-2011-distributional, kim-etal-2014-temporal, kulkarni2014statisticallysignificantdetectionlinguistic, 10.1007/978-3-319-50496-4_18, hamilton-etal-2016-cultural, hamilton-etal-2016-diachronic, kutuzov-etal-2018-diachronic},
a vast collection spanning from 1900 to 2009,
encompassing over 500 billion books in seven languages.
This dataset provides n-grams with corresponding yearly occurrences and frequencies.

\para{Various type of linguistic changes.}
Words have the ability to undergo shifts in meaning over the course of time as a result of various linguistic mechanisms,
including but not limited to \emph{semantic drift} ~\cite{gulordava-baroni-2011-distributional, kulkarni2014statisticallysignificantdetectionlinguistic},
\emph{syntactic alterations} ~\cite{kulkarni2014statisticallysignificantdetectionlinguistic, hamilton-etal-2016-cultural},
\emph{broadening} as opposed to \emph{narrowing} of meaning, and the processes of \emph{amelioration} versus \emph{pejoration}.
These transformations, as highlighted by Hamilton et al.\ (2016), could be driven by \emph{cultural} or \emph{linguistic} factors.
Certain studies concentrate on semantic changes, while others explored the broader evolution that words underwent ~\cite{kim-etal-2014-temporal}, with some works focus on transformations in word usage and meaning ~\cite{gulordava-baroni-2011-distributional, kulkarni2014statisticallysignificantdetectionlinguistic, hamilton-etal-2016-cultural}.
The causes of linguistic changes and the methodologies employed to identify them are outlined in \Cref{tab:related-work}.

\para{Semantic Change.}
Semantic change refers to any change in the meaning(s) of a word over time or acquiring a new sense ~\cite{gulordava-baroni-2011-distributional, 10.1162/opmi_a_00081}.
Kutuzov et al.\ (2018) conducted a survey on semantic shifts, consolidating the existing academic research in this domain.
Their work provides a comprehensive overview of the methodologies and findings related to tracking semantic changes over time using computational techniques.
\vspace{0mm}
\begin{itemize}
    \item \textbf{Co-occurrence Counts:} Gulordava and Baroni (2011) quantify how frequently words appear within the same context.
        They focus on detecting shifts between the 1960s and 1990s using the Google Books Ngram corpus.
        Their approach relies on comparing the similarity of a word's surrounding words in these two periods.
        They define context by considering the words that appear within two positions (a window size of 2) before and after the target word.
        %Example: \'parent\' and \'sleep\'
    \item \para{Neural Language Models:} Kim et al.\ (2014) suggest a new method using \emph{neural language models} to track word meaning evolution.
        They analyze word vectors over time to capture changes.
        Their method compares word vectors using a window size of four from 1900--2009 to detect subtle changes in word usage.
        Additionally, by plotting the time series of a word’s distance to its neighboring words in the model’s vector space, they can visualize the exact period during which the semantic shift occurred.
        Words like `cell' and `gay' show significant changes over time.
    \item \para{Word Embeddings:} Kulkarni et al.\ (2015) introduced method for detecting linguistic change with statistical significance that utilized \emph{word embeddings}.
        Building on the concept of distributed representations proposed by Hinton, they map symbolic data (words) into a continuous vector space where words with similar meanings are positioned close together.
        Their approach incorporates three methods to analyze these embeddings: \emph{frequency-based, syntactic, and distributional}, which are later discussed in  detail in next section.(\Cref{sec:paper})
    \item \para{Clustering:} Liao and Cheng (2016) compared the use of word embeddings with a clustering algorithm called DBSCAN to analyze semantic change.
        Their work investigated which method was more effective for identifying these semantic shifts.
    \item \para{Cultural vs. Linguistic:} Hamilton et al.\ (2016) address the challenge of distinguishing between cultural shifts and linguistic drift, both of which can contribute to semantic change.
        They propose two distinct computational measures based on word embeddings.
        One measure captures global semantic shifts, while the other, captures localized changes that reflect cultural influences.
        Cultural changes like new technologies are related to local neighbourhood change.
        Examples: gay, virus, cell
        These words gained new meanings due to uses in community-specific vernacular (gay) or technological advances (virus, cell).
    \item \para{Diachronic Word Embeddings: } Expanding on the above concepts, their subsequent work investigates recurring patterns in semantic change across different languages.
        They propose two key principles: \emph{the law of conformity}, which suggests that a word's frequency is inversely proportional to the rate of its semantic change.
        In other words, words that are used more frequently tend to experience slower shifts in meaning.
        \emph{The law of innovation}, on the other hand, proposes that words with multiple meanings are more likely to undergo semantic transformations over time.
    \item \para{BERT:} Giulianelli (2020) explores the computational analysis of lexical semantic change using contextualized word representations.
        Contextualized word representations, such as those derived from models like BERT takes into account the context in which words are used.
        This enables a more detailed analysis of how semantic changes occur based on specific word contexts.
    \item \para{Semantic Similarity:} The impact of significant events like the COVID-19 pandemic on language and semantic change has also been a subject of study.
        Laurino et al.\ (2023) explores tracking fast semantic changes through a large-scale word association task, aiming to understand how the collective mental lexicon evolves in response to such global events.
        Their research highlights the dynamic nature of language and how it incorporates new senses.
        For instance, words like `quarantine', `mask', and `social distancing' took on new and prominent meanings in everyday conversation.
\end{itemize}

\para{Syntactic Change.}
The syntactic functionality of a word can evolve by transitioning into a new part-of-speech (POS) category.
Nouns, due to their inherent flexibility in meaning, exhibit a greater tendency to undergo these changes driven by cultural shifts.
While are more likely to participate in gradual semantic changes that follow established linguistic patterns.
\vspace{0mm}
\begin{itemize}
    \item \textbf{Acquiring a new POS:}
    Kulkarni et al.\ assigned part-of-speech (POS) tags to a large collection of text (corpus) and then calculated how likely different words were to appear in certain grammatical contexts (probability distributions).
    They used the word `apple' as an example, which transitioned from being used as a common noun (e.g., a fruit) to a proper noun (referring to the Apple company) after the company's rise in the 1980s.
    \item \para{Nouns vs. Verbs:}
     Hamilton et al.\ (2016) highlight how cultural changes, often influenced by new technologies, are closely tied to transformations within local neighborhoods, particularly sensitive to shifts in nouns.
     On the other hand, linguistic changes, exemplified by subjectification, are more associated with global measures and are particularly responsive to variations in verbs.
     The evolution of words like `actually', `must', and `promise' demonstrate these changes.
     For instance, `must' has transitioned from expressing obligation to indicating necessity, showcasing a common pattern seen in modal verbs.
     Similarly, `promise' shows how performative speech acts undergo significant pragmatic and subjectification-related changes over time.
%    Cultural changes like new technologies are related to local neighbourhood change, which is more sensitive to changes in nouns.
%    Examples: gay, virus, cell
%    Linguistic changes like subjectification is related to global measure, which is more sensitive to change in verbs.
%    Examples: actually, must, promise
%    actually is a case of subjectification
%    must shifted from a deontic/obligation usage (“you must do X”) to a epistemic one (“X must be the case”), exemplifying a regular pattern of change common to many modal verb
%    promise represents the class of shifting “performative speech acts” that undergo rich changes due to their pragmatic uses and subjectification
    \item \para{Acquiring a new sense:}
    Words are complex entities with multiple senses that can evolve over time while their form remains constant, as discussed by (Laurino et al., 2023).
    Their research studies the overall mental lexicon of words, focusing on quantifying the drift of word concepts.
    The study highlights how most words possess a range of meanings that can be added, removed, or modified across different temporal contexts.
\end{itemize}


\vspace{5mm}
%Among the reviewed literature, three studies are particularly pertinent to our analysis of data voids.
%In case of data voids, we want to find shifts from it's previous usage to new usage.
Several studies from our literature review provide valuable insights for addressing data voids in our analysis.
\begin{itemize}
    \item The first being the work by Kulkarni et al.\ which introduces us to time series construction.
Their distributional methods focuses on finding subtle semantic shits to determine the context where a word in used.
This concept aligns perfectly with our goal of uncovering shifts in word usage when encountering data voids.
    \item Second paper by Hamilton et al.\ introduces us to word emebeddings alignment.
Since we want to compare word vectors from different time periods, vectors should be aligned in same coordinate axes.
After aligning the embeddings for individual time periods, we can use the aligned word vectors to compute the semantic displacement that a word has undergone during a certain time-period.
    \item Third one by Laurino et al.\ investigates the impact of the COVID-19 pandemic on word meaning.
One key finding from their work is that words directly related to the pandemic exhibited a greater difference in semantic similarity between pre-pandemic and pandemic time periods.
This suggests that these words underwent a more significant and rapid semantic shift compared to control words not associated with the pandemic.
They also employ semantic similarity analysis to quantify the shifts in meaning for pandemic-related words and provides evidence that the COVID-19 pandemic acted as a catalyst for rapid semantic change.

\end{itemize}

